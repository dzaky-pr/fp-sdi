BAB 1 	PENDAHULUAN

1.1	Latar Belakang
Pencarian semantik menggeser temu balik informasi dari sekadar pencocokan kata kunci menuju pemahaman makna melalui embedding vektor berdimensi tinggi. Pada skala jutaan entri, vector database (VDB) dibutuhkan untuk penyimpanan dan penelusuran approximate nearest neighbor search (ANNS) yang efisien, sekaligus menyediakan fitur sistem seperti payload/metadata, mutasi data, dan persistensi. Praktik benchmarking mutakhir menekankan lingkungan terkontrol yaitu single-machine, pemisahan media penyimpanan vektor + indeks di NVMe SSD terdedikasi agar I/O OS tidak mengganggu, serta pengukuran throughput (QPS), tail latency (P50/P95/P99), dan CPU usage, dilengkapi karakterisasi I/O pada block layer (mis. bpftrace). Untuk fairness dan reproducibility, sistem dijalankan dari official Docker images. Berbeda dari rujukan yang menyertakan LanceDB (non-Docker), studi ini mengecualikan LanceDB agar seluruh sistem berjalan pada Docker resmi yang seragam; parameter indeks disetel terhadap target kualitas hasil (mis. recall@10 ≥ 0,9), dan prosedur uji diseragamkan (setiap eksperimen 30 detik dengan 1.000 query; flush page cache sebelum tiap run; pengulangan 5 kali dan pelaporan rata-rata). Di atas penelitian tersebut, research gap yang ditangani dalam studi ini adalah kebutuhan untuk menerjemahkan angka-angka performa menjadi pedoman arsitektural untuk scalability/performance (QPS, P99, CPU, I/O) dengan metodologi rujukan: single-machine, NVMe terdedikasi, VectorDBBench, 30 detik/1.000 query, flush page cache, 5× ulangan, Docker resmi, dan tuning hingga recall@10 ≥ 0,9. 
Selain itu, banyak studi beroperasi pada skala data jutaan dan mesin dengan tingkat kelas server, sementara kebutuhan praktis di lingkungan pengembangan/akademik sering mensyaratkan replikasi metodologi pada skala yang lebih kecil. Penelitian ini secara eksplisit menyatakan perbedaan terhadap paper rujukan yaitu pada lingkungan uji yang dijalankan pada laptop (dataset diskalakan agar sesuai sumber daya), fokus pada penggunaan Docker (LanceDB dikecualikan karena non-Docker sehingga tidak apples-to-apples), namun seluruh prosedur inti hingga penyetelan indeks ke target recall, waktu run 30 detik, 1.000 query, flush page cache, dan 5 kali pengulangan tetap diikuti penuh. Studi ini tidak menargetkan replikasi angka absolut dari rujukan karena distribusi embedding (dokumen PDF saya) dan spesifikasi mesin berbeda; yang direplikasi adalah metodologi dan pola hubungan (efek concurrency, tuning untuk recall, trade-off ef/nprobe/search_list).

1.2	Rumusan Masalah
Berdasarkan latar belakang tersebut, penelitian ini merumuskan pertanyaan sebagai berikut dengan Docker sebagai deployment utama:
1.	Bagaimana dukungan payload/metadata, filter, dan hybrid search pada Milvus/Qdrant/Weaviate memengaruhi fleksibilitas kueri serta performa pada pipeline PDF → embedding → VDB di lingkungan Docker yang seragam?
2.	Sejauh mana pilihan indeks (HNSW/IVF/DiskANN), proses build index, serta concurrency (ingestion dan query bersamaan) memengaruhi latensi (P50/P95/P99), throughput (QPS), CPU usage, dan pola I/O pada single-node Docker?
Metodologi tuning mengikuti praktik yang adil: parameter indeks disetel hingga recall@10 ≥ 0,9 pada satu sistem acuan lalu dipetakan ke sistem lain; bila suatu indeks tidak tersedia (mis. IVF/DiskANN di Qdrant/Weaviate), digunakan HNSW dengan efSearch dituning hingga mencapai target recall yang sama. Secara operasional, saya menerapkan IVF dengan nlist ≈ 4√n saat build dan menala nprobe hingga recall@10 ≥ 0,9; HNSW dengan M = 16 dan efConstruction = 200 saat build serta menala efSearch hingga recall@10 ≥ 0,9; dan DiskANN (Milvus) dengan menala search_list (serta mencatat BeamWidthRatio bila diuji) hingga recall@10 ≥ 0,9.

1.3	Batasan Masalah
Agar penelitian terfokus dan objektif, perlu ditetapkan beberapa batasan masalah sebagai berikut:
1.	Data hanya akan fokus pada semantic search dokumen PDF teks.
2.	Milvus, Qdrant, dan Weaviate menggunakan official Docker images dengan versi yang dipin (misalkan milvusdb/milvus:2.5.x, qdrant/qdrant:1.14.x, semitechnologies/weaviate:1.31.x, untuk LanceDB dikecualikan karena non-Docker untuk menjaga baseline yang homogen).
3.	Metodologi menggunakan waktu 30 detik/1.000 query per run (di-loop bila habis), flush page cache sebelum tiap run, 5 kali ulangan, tuning untuk recall@10 ≥ 0,9.
4.	Embedding pada dimensi 768/1536 dan dataset diperkecil agar sesuai sumber daya laptop.
5.	Arsitektur menggunakan single-machine/single-node dengan vektor + indeks di NVMe terdedikasi (terpisah dari disk OS).
6.	Indeks dibandingkan antara HNSW, IVF, DiskANN (sesuai dukungan tiap DB dalam konfigurasi Docker).

1.4	Tujuan
Penelitian ini bertujuan mengevaluasi secara sistematis dan kuantitatif keunggulan serta kelemahan Milvus, Qdrant, dan Weaviate ketika dijalankan via Docker pada skenario semantic search dokumen yang identik:
1.	Mengevaluasi perbedaan model data & query serta dampaknya pada pipeline PDF → embedding → VDB dari sisi performa terukur (QPS, P99), agar diperoleh pola payload/metadata, filter, dan hybrid search yang efisien.
2.	Membandingkan waktu build indeks, latensi Top-K (P50/P95/P99), QPS, CPU usage, efisiensi ruang & karakteristik I/O, serta stabilitas saat ingestion+query di Docker single-node, guna menurunkan panduan operasional scalability/performance.

1.5	Manfaat
Hasil studi komparatif ini diharapkan memberi manfaat:
1.	Studi menyediakan baseline yang mudah direplikasi di laptop melalui official Docker images (Milvus, Qdrant, dan Weaviate), prosedur uji yang seragam (30 detik/1.000 query, flush page cache, 5×), dan target kualitas hasil (recall@10) yang konsisten sehingga hasil tetap apples-to-apples meski dataset diperkecil.
2.	Dengan memisahkan media data + indeks ke NVMe (single-node) seperti rujukan, metodologi yang sama dapat diterapkan pada laptop yang hasilnya tetap informatif untuk arsitektur lokal/end-to-end tanpa infrastruktur server kelas berat.
3.	Hasil pengukuran QPS, tail latency (P50/P95/P99), CPU usage, serta karakteristik I/O (via bpftrace) menjadi rujukan kuantitatif saat menguji workload dokumen dan mengendalikan variabel tuning pada skala laptop.
4.	Perbandingan HNSW/IVF/DiskANN termasuk risiko OOM HNSW pada concurrency tinggi akan memberi pedoman memilih indeks dan menala parameter (mis. search_list) sesuai target recall & profil perangkat, sekaligus memahami efek concurrency pada bandwidth per query.
5.	Fokus pada dua dimensi embedding yang umum (768 dan 1536) memastikan temuan relevan untuk pipeline RAG terkini, meski ukuran dataset diperkecil.
6.	Pemetaan hasil uji ke Scalability/Performance: QPS & CPU vs concurrency, serta stabilitas tail-latency (P99) sebagai indikator SLO; plus waktu build/re-index sebagai overhead operasional terukur (tanpa klaim maintainability/reliability).
 
BAB 2 	TINJAUAN PUSTAKA

Bab ini mengulas penelitian-penelitian yang relevan dengan semantic search berbasis embedding dan native vector database (Milvus, Qdrant, Weaviate), dengan fokus pada skenario pencarian dokumen PDF. Ulasan mencakup karya-karya mengenai representasi semantik (misalnya BERT/Sentence-BERT), algoritme approximate nearest neighbor (HNSW, IVF/FAISS, PQ), serta rancangan sistem manajemen data vektor modern. Selain memetakan pendekatan umum di literatur, bagian ini juga menyoroti studi yang secara langsung membahas model data dan bahasa kueri, arsitektur penyimpanan–pengambilan, serta mekanisme terdistribusi (replikasi, partisi, konsistensi) sebagai landasan metodologis bagi eksperimen pada penelitian ini.
2.1	Hasil Penelitian Terdahulu
Studi rujukan terkini mengukur state-of-the-practice vector database pada setup NVMe modern dengan workload generator VectorDBBench, memisahkan media data+indeks ke NVMe tersendiri, serta mencatat I/O traces tingkat blok menggunakan bpftrace. Tiga metrik pokok yang dievaluasi adalah throughput (QPS), tail latency (P99), dan CPU usage; metodologi uji diseragamkan: 30 detik per run, 1.000 query (diulang bila habis), flush page cache pra-run, dan pelaporan rerata+deviasi standar setelah lima ulangan. Dataset yang digunakan merepresentasikan dua dimensi embedding yang lazim pada RAG (768 dan 1536).
Kontribusi utama studi tersebut mencakup pemetaan performa, skalabilitas, dan karakteristik I/O VDB pada NVMe (22 observasi, 3 key findings), serta temuan bahwa storage-based setup (contoh: Milvus+DiskANN) mendominasi random 4 KiB I/O, yang mengindikasikan pemanfaatan bandwidth SSD belum optimal.
Dari sisi I/O, bandwidth baca selama vector search relatif stabil; SSD tidak jenuh (puncak ≈ 658,8 MiB/s ≈ 8,9% dari 7,2 GiB/s). Saat concurrency meningkat, bandwidth per query cenderung turun (≈ 9,5–13,4%); ketika ukuran dataset naik 10×, bandwidth per query DiskANN naik ≈ 8,4–10,1×. Studi juga mengamati skala read bandwidth yang membaik pada dataset kecil namun menurun pada dataset besar saat concurrency tinggi, menandakan bottleneck CPU.
Pada level algoritmik, HNSW muncul sebagai indeks tercepat untuk top-K search di berbagai sistem; pada Milvus, DiskANN secara konsisten mengungguli IVF untuk throughput dan latensi, namun kenaikan search_list (parameter penting DiskANN) memunculkan trade-off—QPS bisa naik signifikan tetapi biaya I/O per query juga meningkat tajam.

2.2	Dasar Teori
Konsep-konsep dasar yang menjadi pijakan penelitian ini bersumber dari jurnal/paper bereputasi dan dokumentasi resmi Qdrant, Milvus, serta Weaviate, untuk memahami prinsip-prinsip inti dalam menyelesaikan permasalahan semantic retrieval pada kumpulan PDF. Subbab ini menjabarkan teori mengenai pemodelan dan bahasa kueri pada vector database, indeks dan jalur retrieval, encoding embedding serta evolusi skema/indeks, dan manajemen data terdistribusi (replikasi, partisi, konsistensi, serta proses latar seperti compaction dan index build). 

2.2.1	Vector Database
Vector database (VDB) adalah sistem manajemen basis data khusus untuk menyimpan, mengindeks, dan men-query embedding vektor berdimensi tinggi beserta atribut terstruktur (payload/metadata) dan kapabilitas operasional layaknya DBMS (CRUD, durability, scaling, filtering/hybrid queries). VDB berbeda dari vector-capable DB atau pustaka ANN murni karena indexing ANN terintegrasi dengan storage engine, query planner, dan fitur ketahanan/skalabilitas sehingga siap untuk beban produksi pada aplikasi AI modern. Definisi dan ruang lingkup ini konsisten dengan survei akademik VDB yang menegaskan fokus pada pengelolaan vektor berdimensi puluhan–ribuan beserta eksekusi kueri campuran (hybrid) dan optimasi penyimpanan, serta ditegaskan pula oleh dokumentasi resmi Qdrant, Milvus, dan Weaviate sebagai DB vektor yang menyimpan objek + vektornya dan mengekspos antarmuka pemodelan/kueri tingkat sistem.

2.2.2	Docker Containerization
Containerization (Docker) dipakai untuk memastikan fairness dan reproducibility: versi/konfigurasi lingkungan distandarkan lintas sistem sehingga hasil uji dapat dibandingkan apples-to-apples. Ketiga DB yang menjadi objek kajian secara resmi mendukung Docker/Docker Compose—Milvus menyediakan panduan install/run berbasis Compose (termasuk prasyarat macOS/CPU/RAM), Qdrant mendistribusikan official image dengan quickstart docker run dan opsi konfigurasi RUN_MODE pada image produksinya, dan Weaviate menyediakan installer serta konfigurator docker-compose.yml untuk kustomisasi runtime. Selain praktik dari dokumentasi vendor, studi rujukan yang saya ikuti juga menjalankan Milvus, Qdrant, dan Weaviate dari official Docker image (sementara LanceDB non-Docker), menegaskan bahwa Docker adalah baseline eksperimen komparatif masa kini.

2.2.3	Semantic Embedding
Semantic embedding memetakan objek (teks/gambar/metadata) ke vektor berdimensi tetap sehingga kemiripan makna dapat diukur melalui metrik jarak (mis. cosine/IP/L2). Model modern seperti Sentence-BERT (SBERT) mengubah arsitektur BERT menjadi siamese/triplet networks agar menghasilkan embedding kalimat yang bermakna dan dapat dibandingkan langsung untuk semantic search skala besar. Dalam praktik VDB, dimensi umum seperti 768 dan 1536 sering dipakai untuk pipeline RAG dan evaluasi.

2.2.4	Approximate Nearest Neighbor (ANN) Search
Pencarian tetangga terdekat eksak tidak skala pada dimensi tinggi, sehingga sistem industri memakai Approximate Nearest Neighbor Search (ANNS) yang menukar sedikit akurasi dengan lonjakan efisiensi. Kualitas hasil biasanya dinilai dengan recall@k, sementara performa diukur lewat throughput (QPS) dan latency percentiles. Beragam struktur indeks—graf (HNSW), cluster-based (IVF), hingga storage-based (DiskANN)—menawarkan trade-off berbeda antara memori, I/O, dan latensi.

2.2.5	Retrieval-Augmented Generation (RAG)
RAG menggabungkan memori non-parametrik (retriever) dengan model generatif: sistem melakukan retrieve dokumen paling relevan (mis. via VDB) lalu generate jawaban berdasar konteks eksternal. Pendekatan ini meningkatkan akurasi pada tugas knowledge-intensive dan mendorong pemakaian embedding & VDB dengan dimensi yang umum di industri.

2.2.6	HNSW (Hierarchical Navigable Small World)
HNSW membangun graf small-world berlapis; pencarian dimulai dari lapisan atas dan disempurnakan ke lapisan bawah, dikendalikan oleh parameter seperti M, efConstruction, dan efSearch. HNSW dikenal cepat serta akurat pada high-recall, namun konsumsi memori bisa besar pada skala tinggi. HNSW banyak menjadi default index di VDB modern.

2.2.7	IVF (Inverted File)
IVF mengelompokkan ruang vektor menjadi sejumlah centroid (k-means/Voronoi). Saat query, sistem hanya memeriksa nprobe klaster terdekat, sehingga ruang pencarian menyempit drastis dengan sedikit penurunan akurasi. Implementasi dan penjelasan rinci tersedia pada dokumentasi Milvus dan FAISS (mis. IndexIVF*, parameter nlist/nprobe).

2.2.8	DiskANN (Storage-based Graph Index)
DiskANN menyimpan sebagian besar struktur indeks/vektor di SSD, memungkinkan billion-scale search pada RAM terbatas. Parameter penting antara lain search_list (cakupan eksplorasi kandidat) dan BeamWidthRatio (tingkat paralelisme I/O per inti). Studi dan dokumentasi menunjukkan peningkatan search_list menaikkan akurasi namun menurunkan throughput/menambah latensi serta bandwidth I/O; meski begitu, pada konfigurasi uji tertentu SSD belum jenuh sehingga tuning perlu menyeimbangkan akurasi dan performa.

2.2.9	Payload & Filtering (Qdrant)
Payload di Qdrant adalah metadata terstruktur (JSON) yang disimpan berdampingan dengan vektor, sehingga memungkinkan filtering berbasis atribut di jalur pencarian (kombinasi must/should/must_not, ekspresi bersarang). Qdrant mendukung on-disk untuk vektor/indeks agar hemat RAM (memanfaatkan memmap) dengan konsekuensi potensi penurunan performa baca. Fitur ini krusial untuk semantic + structured filtering (mis. tipe dokumen, tanggal, user scope).

2.2.10	Hybrid Search (Weaviate)
Hybrid search menggabungkan vector search dengan keyword/BM25 dan melakukan fusi skor (mis. relative score fusion). Pendekatan ini mengurangi risiko semantic drift pada kueri yang mengandung kata kunci penting, serta memberi hasil lebih robust pada dokumen teknis. Weaviate menyediakan konfigurasi hybrid di level kueri/collection dan mendokumentasikan perilaku serta opsi pembobotannya.

2.2.11	Fitur Indeks & Tuning di Milvus/Weaviate/Qdrant
Milvus menyediakan keluarga indeks IVF/HNSW/DiskANN dengan panduan tuning (mis. search_list, BeamWidthRatio untuk DiskANN) dan artikulasi trade-off memori vs latensi. Weaviate mendukung vector index types (HNSW/Flat/Dynamic) yang dapat dipilih per-collection sesuai ukuran data. Qdrant menggunakan HNSW dengan opsi on_disk untuk vektor/indeks, serta konfigurasi storage dan memmap threshold melalui config/env. Pemilihan/tuning indeks harus mempertimbangkan target recall, batas RAM, dan pola I/O SSD.

2.2.12	Storage & Durability: WAL, Compaction, Persistence
Pada VDB modern, Write-Ahead Log (WAL) merekam perubahan sebelum ditulis permanen untuk menjaga durabilitas data, sementara compaction mengonsolidasikan segmen/entri usang agar pemakaian ruang dan latensi tetap terkendali saat ingestion berlangsung; mekanisme persistence/backup mengatur penempatan data pada media penyimpanan. Dalam penelitian ini, komponen-komponen tersebut dipandang sebagai proses latar yang dapat memengaruhi kinerja (mis. throughput, tail-latency, utilisasi CPU, dan pola I/O), namun tidak dievaluasi dari sisi ketahanan/rekoveri. Untuk menjaga fokus ke performa, seluruh eksperimen dijalankan single-machine dengan vektor dan indeks di NVMe SSD terdedikasi; metrik utama mengikuti rujukan, yakni throughput (QPS), P99 tail latency, CPU usage, serta tracing I/O di block layer menggunakan bpftrace. Prosedur pengukuran meniru metodologi rujukan: 30 detik/1.000 query per run (diulang bila habis), flush page cache sebelum tiap run, 5× ulangan, dan tuning indeks hingga recall@10 ≥ 0,9 untuk fairness antar sistem.

2.2.13	Metrik Evaluasi di VDB
Metrik utama mengikuti rujukan: throughput (QPS), latency percentiles (P50/P95/P99), CPU usage, serta karakteristik I/O yang ditangkap di block layer menggunakan bpftrace. Akurasi dijaga dengan recall@10 ≥ 0,9 melalui tuning parameter indeks. Protokol uji: 30 detik/1.000 query per run (loop jika habis), flush page cache sebelum tiap run, 5× ulangan, dan vektor+indeks di NVMe SSD terdedikasi.

 
BAB 3 	METODOLOGI
Bab metodologi menjelaskan alur pengerjaan tugas akhir beserta penjelasan setiap tahapan yang dilakukan. Bagian ini menjadi acuan dalam mengerjakan tugas akhir.

3.1	Metode yang digunakan
Subbab ini memaparkan urutan kerja penelitian dalam sebuah diagram alir yang akan ditampilkan pada Gambar 3.1. Alur dibagi menjadi dua tahap yaitu persiapan serta pelaksanaan dan analisis. Seluruh tahapan diarahkan untuk mendapatkan hasil pengukuran yang adil dan mudah direplikasi pada perangkat laptop menggunakan image resmi Docker untuk Milvus, Qdrant, dan Weaviate. Diagram alur ditunjukkan pada Gambar 3.1
 
Gambar 3.1. Metodologi Pengerjaan Tugas Akhir

3.1.1	Identifikasi Masalah
Tahap awal mendefinisikan masalah inti yang hendak dijawab yaitu bagaimana pilihan indeks dan cara penyimpanan memori atau berbasis penyimpanan memengaruhi throughput pencarian (QPS), latensi ekor P99, pemakaian CPU, dan pola I/O pada media NVMe dalam skenario satu mesin. Rumusan pertanyaan penelitian disusun agar setiap langkah berikutnya terarah dan hasilnya dapat dibandingkan secara objektif pada skala laptop.

3.1.2	Studi Literatur
Tahap ini meninjau ringkas dasar teori dan hasil riset yang relevan tentang approximate nearest neighbor search, rancangan indeks IVF, HNSW, dan DiskANN, serta praktik evaluasi yang lazim digunakan. Tinjauan ini memberi landasan pemilihan metrik QPS P99 CPU dan pelacakan I/O serta alasan memakai dimensi embedding yang umum di sistem RAG. Hasil kajian menjadi rujukan langsung saat menyusun desain eksperimen.

3.1.3	Desain Workload dan Skenario Uji
Tahap ini menyusun beban kerja yang sepadan dengan kemampuan laptop. Dataset diambil dalam bentuk subset terkontrol berukuran seratus ribu hingga lima ratus ribu vektor dengan dimensi yang lazim digunakan. Setiap sesi uji menjalankan seribu query dengan durasi sekitar tiga puluh detik dan menggunakan beberapa tingkat concurrency mulai dari satu hingga mencapai batas stabil. Seluruh pemilihan acak dilakukan dengan seed yang sama (misal seed=42) agar hasil dapat diulang.

3.1.4	Lingkungan Eksperimen Laptop dan Docker
Tahap ini menetapkan perangkat dan perangkat lunak yang dipakai. Pengujian dilakukan pada laptop dengan media NVMe dan seluruh sistem basis data dijalankan memakai Docker dan Compose. Pada satu waktu hanya satu basis data yang aktif untuk menghindari saling memengaruhi. Setiap sistem memakai volume data tersendiri sehingga pemuatan dan pembersihan data dapat dilakukan dengan tertib.

3.1.5	Konfigurasi Sistem dan Parameter Indeks
Tahap ini menguraikan sistem yang diuji serta parameter yang relevan. Milvus digunakan dengan indeks IVF, HNSW, dan DiskANN; Qdrant menggunakan HNSW; dan Weaviate menggunakan HNSW. Parameter awal disiapkan mengikuti praktik umum lalu disesuaikan saat penalaan misalnya nprobe untuk IVF; efSearch untuk HNSW (build: M=16, efConstruction=200); serta search_list dan BeamWidthRatio untuk DiskANN. Seluruh pengaturan dicatat dalam tabel konfigurasi agar mudah ditelusuri.

3.1.6	Baseline SSD dengan Flexible I/O Tester (fio)
Tahap ini mengukur kemampuan dasar media penyimpanan agar kapasitas perangkat diketahui sebelum menilai hasil basis data. Pekerjaan meliputi uji baca acak blok kecil dan baca sekuensial untuk mendapatkan angka IOPS latensi dan bandwidth. Hasil baseline ini dipakai sebagai pembanding ketika menafsir apakah hambatan utama berasal dari CPU atau dari perangkat penyimpanan.

3.1.7	Penetapan Target Akurasi
Tahap ini menegaskan kualitas hasil yang harus dipenuhi sehingga perbandingan menjadi adil. Target yang digunakan adalah recall pada sepuluh minimal nol koma sembilan. Penalaan dilakukan sampai target tercapai dengan menyesuaikan nprobe pada IVF, efSearch pada HNSW (build tetap M=16, efConstruction=200), dan search_list pada DiskANN. Setelah target terpenuhi barulah hasil performa dicatat sebagai bagian dari komparasi.

3.1.8	Warm up dan Kebijakan Cache
Tahap ini memastikan kondisi awal setiap sesi uji seragam agar hasil tidak berat sebelah. Setiap kombinasi pengujian diawali pemanasan singkat kemudian dilakukan penyegaran cache sesuai kemampuan sistem. Bila akses root tersedia maka pembersihan page cache dilakukan, bila tidak maka digunakan jeda dan pemanasan ulang. Prosedur ini ditulis sebagai langkah baku yang diulang pada semua sesi.

3.1.9	Pelaksanaan Eksperimen
Tahap ini menjalankan pengukuran inti untuk setiap kombinasi basis data, indeks, dan dataset. Urutan kerja dimulai dari pemuatan data, pembuatan indeks, pemanasan, lalu eksekusi beban selama tiga puluh detik atau hingga seribu query selesai. Pengujian diulang sebanyak lima kali untuk mendapatkan rata-rata yang stabil dan tingkat concurrency dinaikkan bertahap hingga mencapai batas yang aman di laptop.

3.1.10	Pencatatan Metrik
Tahap ini mengumpulkan semua data yang diperlukan untuk analisis. Metrik yang dicatat mencakup QPS, latensi P99, dan pemakaian CPU. Jika sistem memungkinkan, dilakukan pula pelacakan I/O pada level blok untuk melihat ukuran dan pola akses baca. Seluruh hasil disimpan dalam berkas CSV atau JSON dengan skema penamaan yang konsisten sehingga mudah diproses selanjutnya.

3.1.11	Analisis Data dan Evaluasi Hasil
Tahap ini membaca dan menafsirkan hasil pengujian. Analisis dilakukan dengan memetakan QPS terhadap concurrency serta P99 terhadap concurrency, lalu membandingkannya dengan hasil baseline fio untuk mengindikasikan bottleneck (CPU-bound vs SSD-bound). Penilaian diarahkan untuk mengidentifikasi sumber hambatan apakah dominan pada CPU memori atau perangkat penyimpanan dan merangkum implikasi praktis bagi penggunaan di lingkungan laptop.

3.1.12	Studi Sensitivitas Parameter
Tahap ini mengeksplorasi pengaruh perubahan parameter terhadap akurasi dan performa. Nilai nprobe, efSearch, search_list, dan bila digunakan BeamWidthRatio divariasikan secara terukur sambil menjaga target recall. Hasil pengamatan menunjukkan titik pengaturan yang seimbang antara kecepatan dan kualitas hasil sehingga dapat direkomendasikan sebagai setelan yang memadai untuk skala laptop dan beban kerja yang diuji.

3.2	Rencana Jadwal Kegiatan
Table 3.1 Rencana Jadwal Kegiatan Penelitian
No	Nama Kegiatan	Minggu Ke-
		1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16
A.	Tahap Persiapan
1.	Identifikasi Masalah																
2.	Studi Literatur																
3.	Desain Workload & Skenario Uji																
4.	Lingkungan Eksperimen																
5.	Konfigurasi Sistem & Parameter Indeks																
6.	Baseline SSD																
7.	Penetapan Target Akurasi																
8.	Warm-up & Kebijakan Flush Cache																
B.	Tahap Pelaksanaan Penelitian
9.	Pelaksanaan Eksperimen																
10.	Pencatatan Metrik																
11.	Analisis Data & Evaluasi Hasil																
12.	Studi Sensitivitas																

DAFTAR PUSTAKA
Aumüller, M., Bernhardsson, E., & Faithfull, A. (2020). ANN-Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms. Information Systems, 87, 101374. https://doi.org/10.1016/j.is.2019.101374
Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT 2019 (pp. 4171–4186). Association for Computational Linguistics. https://aclanthology.org/N19-1423
Gilbert, S., & Lynch, N. (2002). Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services. ACM SIGACT News, 33(2), 51–59. https://doi.org/10.1145/564585.564601
Guo, R., Sun, P., Lindgren, E., Geng, Q., Simcha, D., Chern, F., & Kumar, S. (2020). Accelerating large-scale inference with Anisotropic Vector Quantization. In Proceedings of the 37th International Conference on Machine Learning (ICML 2020). (ScaNN). https://arxiv.org/abs/1908.10396
Han, Y., Liu, C., & Wang, P. (2023). A comprehensive survey on vector database: Storage and retrieval technique, challenge. arXiv preprint arXiv:2310.11703. https://arxiv.org/abs/2310.11703
Jégou, H., Douze, M., & Schmid, C. (2011). Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(1), 117–128. https://doi.org/10.1109/TPAMI.2010.57
Johnson, J., Douze, M., & Jégou, H. (2017). Billion-scale similarity search with GPUs. arXiv preprint arXiv:1702.08734. https://arxiv.org/abs/1702.08734
Manning, C. D., Raghavan, P., & Schütze, H. (2008). Introduction to Information Retrieval. Cambridge University Press. (Online edition). https://nlp.stanford.edu/IR-book/
Malkov, Y. A., & Yashunin, D. A. (2020). Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(4), 824–836. https://doi.org/10.1109/TPAMI.2018.2889473
Milvus Documentation. (n.d.-a). Architecture overview (v2.x). Retrieved September 17, 2025, from https://milvus.io/docs/architecture_overview.md
Milvus Documentation. (n.d.-b). Index types. Retrieved September 17, 2025, from https://milvus.io/docs/index.md
Milvus Documentation. (n.d.-c). Performance FAQ (compaction) (v2.3.x). Retrieved September 17, 2025, from https://milvus.io/docs/v2.3.x/performance_faq.md
Milvus Documentation. (n.d.-d). Java API: manualCompact()/getCompactionState() (v2.2–2.6). Retrieved September 17, 2025, from https://milvus.io/api-reference/java/v2.2.x/Management/manualCompact%28%29.md and https://milvus.io/api-reference/java/v2.6.x/v1/Management/getCompactionStateWithPlans.md
Milvus Documentation. (n.d.-e). Guarantee the consistency of hybrid search. Retrieved September 17, 2025, from https://milvus.io/docs/consistency_hybrid_search.md
NIST. (n.d.). trec_eval: Evaluation software for TREC. Retrieved September 17, 2025, from https://trec.nist.gov/trec_eval/
O’Neil, P., Cheng, E., Gawlick, D., & O’Neil, E. (1996). The log-structured merge-tree (LSM-tree). Acta Informatica, 33(4), 351–385. https://link.springer.com/article/10.1007/s002360050048
Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence embeddings using Siamese BERT networks. In Proceedings of EMNLP-IJCNLP 2019 (pp. 3982–3992). Association for Computational Linguistics. https://aclanthology.org/D19-1410
Wang, J., Yi, X., Guo, R., Jin, H., Xu, P., Li, S., … Xie, C. (2021). Milvus: A purpose-built vector data management system. In Proceedings of SIGMOD ’21. ACM. https://doi.org/10.1145/3448016.3457550
Ren, Z., Doekemeijer, K., Apparao, P., & Trivedi, A. (2025). Storage-Based Approximate Nearest Neighbor Search: What are the Performance, Cost, and I/O Characteristics? IISWC 2025. (Artefak/Traces: Zenodo 10.5281/zenodo.16916496).
Weaviate Documentation. (n.d.-a). Vector index (HNSW). Retrieved September 17, 2025, from https://docs.weaviate.io/weaviate/config-refs/indexing/vector-index
Weaviate Documentation. (n.d.-b). Replication architecture. Retrieved September 17, 2025, from https://docs.weaviate.io/weaviate/concepts/replication-architecture
Weaviate Documentation. (n.d.-c). Consistency. Retrieved September 17, 2025, from https://docs.weaviate.io/weaviate/concepts/replication-architecture/consistency
Weaviate Documentation. (n.d.-d). Hybrid search. Retrieved September 17, 2025, from https://docs.weaviate.io/weaviate/search/hybrid
Weaviate Documentation. (n.d.-e). Modules. Retrieved September 17, 2025, from https://docs.weaviate.io/weaviate/concepts/modules
Weaviate Documentation. (n.d.-f). Queries & Filters (GraphQL). Retrieved September 17, 2025, from https://weaviate.io/developers/weaviate/api/graphql/queries and https://weaviate.io/developers/weaviate/api/graphql/filters 
