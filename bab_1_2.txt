BAB 1 	PENDAHULUAN

1.1	Latar Belakang
Pencarian Pencarian semantik (semantic search) mengubah temu balik informasi dari pencocokan kata kunci menjadi pemahaman makna melalui embedding vektor berdimensi tinggi. Pada skala puluhan-ratusan ribu entri di perangkat kelas laptop, dibutuhkan vector database (VDB) yang efisien untuk approximate nearest neighbor search (ANNS) sekaligus tetap menyediakan fitur sistem (payload/metadata, filtering, durabilitas). Praktik benchmarking modern menekankan lingkungan single-machine berbasis Docker, penyimpanan NVMe terdedikasi agar noise I/O minimal, dan metrik yang menyorot throughput (QPS) serta tail-latency (P50/P95/P99), ditambah pengukuran CPU dan jejak I/O pada lapisan blok.
Penelitian ini sengaja memposisikan kelas laptop sebagai medan uji. Fokusnya adalah dua VDB populer yaitu Qdrant dan Weaviate dengan indeks HNSW yang sama-sama tersedia sebagai image resmi Docker. Penekanan bukan pada angka absolut, tetapi pola skalabilitas awal (QPS, P99, CPU, I/O) saat sistem “dipaksa” dalam batas wajar laptop melalui grid konkurensi kecil dan penalaan ef sampai memenuhi kualitas hasil minimum (recall@10 ≥ 0,9).
1.2	Rumusan Masalah
Berdasarkan latar belakang tersebut, penelitian ini merumuskan pertanyaan sebagai berikut dengan Docker sebagai deployment utama:
1.	Bagaimana perbedaan model kueri dan fitur sistem (seperti payload filtering serta opsi hybrid search pada Weaviate) memengaruhi throughput (QPS), tail latency (P50/P95/P99), penggunaan CPU, dan karakteristik I/O pada pipeline PDF → embedding → vector database yang dijalankan di lingkungan Docker single-node berbasis NVMe internal?
2.	Bagaimana penyetelan parameter HNSW-khususnya nilai efSearch pada Qdrant dan ef pada Weaviate-mempengaruhi keseimbangan antara kualitas hasil pencarian (recall@10 ≥ 0,9) dan kinerja sistem (QPS, latensi, CPU, I/O)?
3.	Bagaimana peningkatan tingkat konkurensi (1-2 worker) memengaruhi skalabilitas awal, serta apakah terdapat indikasi bottleneck CPU-bound atau I/O-bound saat sistem dijalankan pada perangkat berspesifikasi laptop dengan sumber daya terbatas?
4.	Bagaimana sensitivitas performa Qdrant dan Weaviate terhadap dimensi embedding (384, 768, 1536) dan ukuran dataset (10 k - 50 k vektor), serta apa implikasinya bagi efisiensi dan skalabilitas sistem pencarian semantik berbasis HNSW di lingkungan laptop?
1.3	Batasan Masalah
Agar penelitian terfokus dan objektif, perlu ditetapkan beberapa batasan masalah sebagai berikut:
1.	Sistem yang diuji hanya meliputi Qdrant dan Weaviate yang sama-sama menggunakan indeks HNSW untuk memastikan perbandingan yang adil dan sebanding.
2.	Milvus tidak disertakan dalam pengujian karena kebutuhan sumber daya yang tinggi, ketidakstabilan pada macOS, dan kompleksitas API yang tidak sesuai untuk lingkungan laptop.
3.	Lingkungan eksperimen dijalankan sepenuhnya di Docker dengan single-machine setup dan NVMe internal storage agar hasilnya terkontrol dan dapat direproduksi.
4.	Dataset yang digunakan bersifat kecil hingga menengah, dengan ukuran antara 10 ribu hingga 50 ribu vektor, serta dimensi embedding 384, 768, dan 1536 agar tetap sesuai dengan kapasitas laptop.
5.	Pengujian dilakukan secara sekuensial pada setiap database untuk menghindari kompetisi sumber daya CPU dan I/O.
6.	Parameter HNSW yang diuji terbatas pada ef_search (Qdrant) dan ef (Weaviate) untuk menilai dampaknya terhadap recall dan kinerja sistem.
7.	Analisis performa difokuskan pada throughput (QPS), tail latency (P50, P95, P99), penggunaan CPU, dan karakteristik I/O pada NVMe internal.
8.	Seluruh eksperimen dijalankan di perangkat dengan spesifikasi MacBook Pro RAM 8 GB dan internal SSD NVMe 256 GB, menggunakan Python versi 3.13 di Docker container berbasis python:3.13-slim.
9.	Hasil penelitian ini tidak membahas aspek keamanan, biaya lisensi, atau integrasi eksternal seperti LanceDB atau sistem multi-node.
1.4	Tujuan
Penelitian ini memiliki beberapa tujuan utama yang ingin dicapai sebagai berikut.
1.	Mengukur dan membandingkan performa Qdrant dan Weaviate dalam menjalankan pencarian semantik berbasis HNSW di lingkungan Docker single-node dengan penyimpanan NVMe internal menggunakan parameter eksperimen yang identik.
2.	Menentukan pengaruh penyetelan parameter HNSW terutama nilai ef_search pada Qdrant dan ef pada Weaviate terhadap kualitas hasil pencarian yang diukur melalui nilai recall @ 10 dan terhadap metrik kinerja seperti QPS, P50, P95, P99, penggunaan CPU, serta aktivitas I/O.
3.	Mengevaluasi skalabilitas awal kedua sistem dengan tingkat konkurensi rendah yaitu satu hingga dua worker untuk mengetahui sejauh mana peningkatan beban dapat dipertahankan tanpa menimbulkan bottleneck pada CPU maupun I/O.
4.	Menghasilkan baseline eksperimen yang dapat direplikasi di perangkat dengan spesifikasi kelas laptop menggunakan Docker serta menghasilkan artefak uji seperti skrip benchmarking, laporan hasil, grafik kinerja, dan analisis bottleneck otomatis.
5.	Memberikan pemahaman kuantitatif tentang efisiensi dan batas kinerja sistem pencarian semantik yang hemat sumber daya sehingga dapat dijadikan acuan bagi penelitian dan pengembangan aplikasi berbasis vector database di lingkungan komputasi terbatas.
1.5	Manfaat
Hasil studi komparatif ini diharapkan memberi manfaat:
1.	Menjadi acuan bagi penelitian selanjutnya dalam vector database khususnya pada topik efisiensi dan skalabilitas di perangkat dengan sumber daya terbatas.
2.	Memberikan gambaran empiris tentang performa dua sistem basis data vektor berbasis HNSW yaitu Qdrant dan Weaviate dalam konteks pencarian semantik terhadap dokumen PDF menggunakan konfigurasi eksperimen yang mudah direplikasi.
3.	Menyediakan dataset, skrip benchmarking, serta laporan hasil yang dapat digunakan kembali untuk validasi atau pengembangan metode pengujian baru pada sistem pencarian semantik.
4.	Mendukung pengembangan sistem pencarian cerdas yang ringan dan hemat sumber daya untuk diterapkan pada skala laptop, laboratorium kecil, maupun proyek riset pendidikan tinggi.
5.	Memberikan kontribusi praktis bagi pengembang, peneliti, dan pelaku industri kecil yang membutuhkan tolok ukur kinerja vector database dalam membangun aplikasi berbasis pencarian semantik menggunakan teknologi open source dan Docker. 
BAB 2 	TINJAUAN PUSTAKA

Bab ini mengulas penelitian-penelitian yang relevan dengan semantic search berbasis embedding dan native vector database (Milvus, Qdrant, Weaviate), dengan fokus pada skenario pencarian dokumen PDF. Ulasan mencakup karya-karya mengenai representasi semantik (misalnya BERT/Sentence-BERT), algoritme approximate nearest neighbor (HNSW, IVF/FAISS, PQ), serta rancangan sistem manajemen data vektor modern. Selain memetakan pendekatan umum di literatur, bagian ini juga menyoroti studi yang secara langsung membahas model data dan bahasa kueri, arsitektur penyimpanan–pengambilan, serta mekanisme terdistribusi (replikasi, partisi, konsistensi) sebagai landasan metodologis bagi eksperimen pada penelitian ini.
2.1	Hasil Penelitian Terdahulu
Penelitian komparatif dan benchmarking untuk approximate nearest neighbor search (ANNS) telah dipopulerkan oleh ANN-Benchmarks, sebuah kerangka uji yang menstandarkan metrik kualitas (mis. recall@k) dan kinerja (mis. throughput) lintas algoritme dan implementasi, sehingga memungkinkan evaluasi adil pada berbagai himpunan data dan dimensi embedding yang berbeda . Dalam ranah indeks berbasis graf, Hierarchical Navigable Small World (HNSW) terbukti efisien karena struktur multi-lapisnya yang memadukan eksplorasi global dan lokal untuk menurunkan latensi pencarian di ruang berdimensi tinggi. 
Di sisi kompresi vektor, Product Quantization (PQ) menurunkan jejak memori dan biaya I/O dengan mendekomposisi ruang vektor ke sub-ruang dan mengkuantisasi masing-masingnya, sehingga memungkinkan pencarian skala besar dengan memori terbatas—dengan kompromi akurasi yang dapat dikendalikan melalui ukuran kodebook.
Terbaru, sebuah survei komprehensif mengenai vector database memetakan desain arsitektur, fitur sistem (payload/filtering, hybrid search), serta strategi indeks/populasi data, dan menekankan bahwa sebagian besar sistem modern mengandalkan variasi HNSW untuk dense vectors dan mekanisme hybrid untuk menggabungkan sinyal sparse+dense.
Dokumentasi resmi Qdrant dan Weaviate sendiri menunjukkan arah serupa: Qdrant menonjol pada payload-aware filtering dan penalaan parameter HNSW, sedangkan Weaviate menyediakan hybrid search (BM25 + vektor) sebagai fitur bawaan untuk fleksibilitas relevansi .
2.2	Dasar Teori
Konsep-konsep dasar yang menjadi pijakan penelitian ini bersumber dari jurnal/paper bereputasi dan dokumentasi resmi Qdrant, Milvus, serta Weaviate, untuk memahami prinsip-prinsip inti dalam menyelesaikan permasalahan semantic retrieval pada kumpulan PDF. Subbab ini menjabarkan teori mengenai pemodelan dan bahasa kueri pada vector database, indeks dan jalur retrieval, encoding embedding serta evolusi skema/indeks, dan manajemen data terdistribusi (replikasi, partisi, konsistensi, serta proses latar seperti compaction dan index build). 
2.2.1	Vector Database
Vector database adalah sistem penyimpanan dan temu balik yang mengelola representasi vektor berdimensi tinggi dari objek (teks, gambar, dll.) dan mengeksekusi kueri kemiripan berdasarkan metrik tertentu (mis. cosine) di atas indeks khusus agar latensi tetap rendah pada skala data besar. Survei mutakhir menegaskan elemen kunci VDB modern: (i) indeks ANN (sering HNSW) untuk dense vectors, (ii) fitur sistem seperti payload/metadata dengan filtering deklaratif, dan (iii) mode hybrid yang memadukan sinyal sparse dan dense untuk meningkatkan relevansi end-to-end. Implementasi praktisnya tampak pada Qdrant (payload + filtering + HNSW) dan Weaviate (HNSW + hybrid/BM25).
2.2.2	Docker Containerization
Containerization (Docker) dipakai untuk memastikan fairness dan reproducibility: versi/konfigurasi lingkungan distandarkan lintas sistem sehingga hasil uji dapat dibandingkan apples-to-apples. Ketiga DB yang menjadi objek kajian secara resmi mendukung Docker/Docker Compose—Milvus menyediakan panduan install/run berbasis Compose (termasuk prasyarat macOS/CPU/RAM), Qdrant mendistribusikan official image dengan quickstart docker run dan opsi konfigurasi RUN_MODE pada image produksinya, dan Weaviate menyediakan installer serta konfigurator docker-compose.yml untuk kustomisasi runtime. Selain praktik dari dokumentasi vendor, studi rujukan yang saya ikuti juga menjalankan Milvus, Qdrant, dan Weaviate dari official Docker image (sementara LanceDB non-Docker), menegaskan bahwa Docker adalah baseline eksperimen komparatif masa kini.
2.2.3	Semantic Embedding
Semantic embedding memetakan objek (teks/gambar/metadata) ke vektor berdimensi tetap sehingga kemiripan makna dapat diukur melalui metrik jarak (mis. cosine/IP/L2). Model modern seperti Sentence-BERT (SBERT) mengubah arsitektur BERT menjadi siamese/triplet networks agar menghasilkan embedding kalimat yang bermakna dan dapat dibandingkan langsung untuk semantic search skala besar. Dalam praktik VDB, dimensi umum seperti 768 dan 1536 sering dipakai untuk pipeline RAG dan evaluasi.
2.2.4	Approximate Nearest Neighbor Search (ANNS) 
ANNS bertujuan menemukan tetangga terdekat dengan biaya waktu jauh lebih rendah dibanding pencarian eksak pada ruang berdimensi tinggi, dengan trade-off akurasi vs kecepatan yang dikendalikan parameter algoritme. Dalam praktik benchmarking, recall@k umum dipakai untuk mengukur kualitas hasil relatif terhadap ground truth eksak, sementara throughput (QPS) dan latensi memotret kinerja; metrik-metrik ini dipopulerkan dan distandardisasi oleh ANN-Benchmarks.
2.2.5	Retrieval-Augmented Generation (RAG)
RAG menggabungkan memori non-parametrik (retriever) dengan model generatif: sistem melakukan retrieve dokumen paling relevan (mis. via VDB) lalu generate jawaban berdasar konteks eksternal. Pendekatan ini meningkatkan akurasi pada tugas knowledge-intensive dan mendorong pemakaian embedding & VDB dengan dimensi yang umum di industri.
2.2.6	HNSW (Hierarchical Navigable Small World)
HNSW membangun graf navigasi berlapis: lapisan atas yang jarang memfasilitasi lompatan global, lalu turun ke lapisan lebih padat untuk pemurnian lokal. Parameter kunci: M (derajat maksimum/“maxConnections”) dan efConstruction (kualitas saat membangun indeks), serta ef/efSearch saat kueri—semakin besar ef, semakin tinggi peluang mencapai recall yang diinginkan namun dengan latensi lebih besar. Formulasi dan analisis kompleksitasnya dibahas rinci dalam artikel TPAMI, dan eksposisi praktis parameter ef pada Qdrant/Weaviate tersedia di dokumentasi resmi (mis. hnsw_ef/ef)
2.2.7	Product Quantization (PQ) untuk Kompresi Vektor
PQ menurunkan ukuran penyimpanan dan bandwidth memori/I-O dengan mempartisi vektor menjadi sub-vektor dan mengkuantisasi masing-masing menggunakan codebook terpisah; pencarian dilakukan dalam ruang terkuantisasi melalui tabel jarak ter-precompute. Teknik ini menjadi landasan banyak sistem ANN skala besar dan sering dipadukan dengan struktur indeks lainnya untuk keseimbangan memori-latensi-recall yang lebih baik.
2.2.8	Metrik Evaluasi untuk Studi Ini
Merujuk praktik benchmarking ANN, eval akan menekankan: kualitas melalui recall@10, kinerja melalui throughput (QPS) serta latensi p-percentile (P50/P95/P99) guna menangkap tail latency, dan utilisasi sumber daya (CPU, serta indikasi I/O). ANN-Benchmarks menjadi rujukan standar untuk definisi recall@k dan evaluasi kinerja terukur lintas algoritme/implementasi.
2.2.9	Payload & Filtering (Qdrant)
Payload di Qdrant adalah metadata terstruktur (JSON) yang disimpan berdampingan dengan vektor, sehingga memungkinkan filtering berbasis atribut di jalur pencarian (kombinasi must/should/must_not, ekspresi bersarang). Qdrant mendukung on-disk untuk vektor/indeks agar hemat RAM (memanfaatkan memmap) dengan konsekuensi potensi penurunan performa baca. Fitur ini krusial untuk semantic + structured filtering (mis. tipe dokumen, tanggal, user scope).
2.2.10	Hybrid Search (Weaviate)
Hybrid search menggabungkan vector search dengan keyword/BM25 dan melakukan fusi skor (mis. relative score fusion). Pendekatan ini mengurangi risiko semantic drift pada kueri yang mengandung kata kunci penting, serta memberi hasil lebih robust pada dokumen teknis. Weaviate menyediakan konfigurasi hybrid di level kueri/collection dan mendokumentasikan perilaku serta opsi pembobotannya.
2.2.11	Filtering & Hybrid Search pada Sistem yang Dibandingkan
Qdrant menyediakan payload (metadata JSON) dengan filtering deklaratif (match/range/boolean) yang dapat dipadukan dengan pencarian vektor untuk mempersempit kandidat tanpa membebani model embedding, berguna saat fitur penting tidak terekspresikan penuh dalam vektor. Weaviate menyediakan hybrid search yang menggabungkan skor BM25 (sparse) dan kemiripan vektor (dense) melalui skema fusi/α-weighting, bermanfaat untuk kueri yang membutuhkan presisi kata kunci sekaligus pemahaman semantik.
2.2.12	Storage & Durability: WAL, Compaction, Persistence
Pada VDB modern, Write-Ahead Log (WAL) merekam perubahan sebelum ditulis permanen untuk menjaga durabilitas data, sementara compaction mengonsolidasikan segmen/entri usang agar pemakaian ruang dan latensi tetap terkendali saat ingestion berlangsung; mekanisme persistence/backup mengatur penempatan data pada media penyimpanan. Dalam penelitian ini, komponen-komponen tersebut dipandang sebagai proses latar yang dapat memengaruhi kinerja (mis. throughput, tail-latency, utilisasi CPU, dan pola I/O), namun tidak dievaluasi dari sisi ketahanan/rekoveri. Untuk menjaga fokus ke performa, seluruh eksperimen dijalankan single-machine dengan vektor dan indeks di NVMe SSD terdedikasi; metrik utama mengikuti rujukan, yakni throughput (QPS), P99 tail latency, CPU usage, serta tracing I/O di block layer menggunakan bpftrace. Prosedur pengukuran meniru metodologi rujukan: 30 detik/1.000 query per run (diulang bila habis), flush page cache sebelum tiap run, 5× ulangan, dan tuning indeks hingga recall@10 ≥ 0,9 untuk fairness antar sistem.

2.2.13	Metrik Evaluasi di VDB
Metrik utama mengikuti rujukan: throughput (QPS), latency percentiles (P50/P95/P99), CPU usage, serta karakteristik I/O yang ditangkap di block layer menggunakan bpftrace. Akurasi dijaga dengan recall@10 ≥ 0,9 melalui tuning parameter indeks. Protokol uji: 30 detik/1.000 query per run (loop jika habis), flush page cache sebelum tiap run, 5× ulangan, dan vektor+indeks di NVMe SSD terdedikasi.
